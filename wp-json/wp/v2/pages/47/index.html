{"id":47,"date":"2023-09-06T17:38:53","date_gmt":"2023-09-06T17:38:53","guid":{"rendered":"http:\/\/localhost:10023\/?page_id=47"},"modified":"2023-12-28T14:37:09","modified_gmt":"2023-12-28T14:37:09","slug":"research","status":"publish","type":"page","link":"http:\/\/localhost:10023\/research\/","title":{"rendered":"Research"},"content":{"rendered":"\n<p><em>Agency<\/em><\/p>\n\n\n\n<p>\u2014 Are current models built as if the AI system pursues its ends? If yes, does this speak for a radical shift, toward models oriented toward human final ends?<\/p>\n\n\n\n<p>\u2014 Should AI models try to emulate that human decision-making is fundamentally concerned with sustaining human life and acting \u201cunder the guise of the good,\u201d in particular, under the guise of what agents take to be well-lived human lives?<\/p>\n\n\n\n<p>\u2014 Who is responsible for decisions that AI makes? Is the AI-system itself responsible, or are its creators responsible for the AI\u2019s decisions?<\/p>\n\n\n\n<p><em>Ethical Values<\/em><\/p>\n\n\n\n<p>\u2014 Are there values, for example, related to the survival of humankind, that neither human beings nor intelligent machines should override?<\/p>\n\n\n\n<p>\u2014 Can the special salience of moral considerations in human reasoning be simulated by attention mechanisms?<\/p>\n\n\n\n<p>\u2014 Ethics is concerned with how human beings should live. Does this mean that AI models should ask \u201cwhat should a human agent do?\u201d (as opposed to \u201cwhat should one do?\u201d).<\/p>\n\n\n\n<p><em>Truth and Other Epistemic Values<\/em><\/p>\n\n\n\n<p>\u2014 What is the role of epistemic norms, for example, norms that request attention to evidence, careful thinking, etc., in AI models?<\/p>\n\n\n\n<p>\u2014 Is sensitivity to value an \u201cextra\u201d dimension of artificial intelligence, to be added to existing systems? Alternatively, are \u201cethical abilities\u201d integrated dimensions of the \u201cthinking abilities\u201d of AI systems, such that they improve along with them?<\/p>\n\n\n\n<p>\u2014 What is an LLM\u2019s relationship to the truth or falsity of its outputs? What does it mean for an LLM to \u201ctell the truth,\u201d \u201clie,\u201d \u201challucinate,\u201d etc.? Can AI have virtues such as honesty?<\/p>\n\n\n\n<p><em>Mental States<\/em><\/p>\n\n\n\n<p>\u2014 We don\u2019t know whether AI will ever have mental states such as intentions and beliefs. Lying arguably involves both: an intention to deceive and saying something one believes to be false. Is it a mere metaphor to describe AI-output in terms of truth-telling versus lying?<\/p>\n\n\n\n<p>\u2014 An AI-system may be said to have \u201cinformation\u201d: Does it \u201cbelieve\u201d the things it can provide as information? Does it \u201cknow\u201d them? What are the functional analogues to mental states such as belief and knowledge?<\/p>\n\n\n\n<p>\u2014 The ValuesLab asks how questions of interpretability of AI systems bear on ethics; for example, are ethical\/moral questions ones where it is especially important to not only have the answer, but also understand how to arrive at the answer?<\/p>\n\n\n\n<p>\u2014 Should AI models try to emulate the roles of emotion and desiderative\/aversive attitudes in human decision-making? If yes, how?<\/p>\n\n\n\n<p><em>Flawed Thinking<\/em><\/p>\n\n\n\n<p>\u2014 Should value integration start from the premise that intelligent machines help us to be better thinkers? How does this premise relate to the much-asked question of whether intelligent machines are, or soon are, better thinkers than we are?<\/p>\n\n\n\n<p>\u2014 Via the corpora of text, images, etc., that LLMs \u201cingest,\u201d they inherit flaws of human thinking, e.g., jumping to conclusions, fallacies. Which dimensions of human reasoning do we want to reproduce? Which dimensions of human reasoning can be improved with the help of machines?<\/p>\n\n\n\n<p>\u2014 In human beings, informal fallacies are often treated as \u201cshortcuts\u201d or \u201cfast track\u201d thinking, saving time and mental energy in resource limited environments. Are we aiming for AI without any such \u201cshortcuts\u201d? If yes, this would constitute a major difference between human and machine reasoning.<\/p>\n\n\n\n<p><em>Pluralism and Disagreement<\/em><\/p>\n\n\n\n<p>\u2014 How can computational intelligence recognize value pluralism, disagreement, and historical changes in evaluative outlooks?<\/p>\n\n\n\n<p>\u2014 How can computational intelligence recognize that human evaluative outlooks tend to be fragmented and inconsistent, a mix of values, principles, and deep-seated affective attitudes?<\/p>\n\n\n\n<p>\u2014 What is the effect of adding an extensive curriculum in ethics, including works that defend a range of approaches, to the training of an AI model?<\/p>\n","protected":false},"excerpt":{"rendered":"<p>Agency \u2014 Are current models built as if the AI system pursues its ends? If yes, does this speak for a radical shift, toward models oriented toward human final ends? \u2014 Should AI models try to emulate that human decision-making is fundamentally concerned with sustaining human life and acting \u201cunder the guise of the good,\u201d [&hellip;]<\/p>\n","protected":false},"author":1,"featured_media":0,"parent":0,"menu_order":0,"comment_status":"closed","ping_status":"closed","template":"","meta":{"footnotes":""},"_links":{"self":[{"href":"http:\/\/localhost:10023\/wp-json\/wp\/v2\/pages\/47"}],"collection":[{"href":"http:\/\/localhost:10023\/wp-json\/wp\/v2\/pages"}],"about":[{"href":"http:\/\/localhost:10023\/wp-json\/wp\/v2\/types\/page"}],"author":[{"embeddable":true,"href":"http:\/\/localhost:10023\/wp-json\/wp\/v2\/users\/1"}],"replies":[{"embeddable":true,"href":"http:\/\/localhost:10023\/wp-json\/wp\/v2\/comments?post=47"}],"version-history":[{"count":15,"href":"http:\/\/localhost:10023\/wp-json\/wp\/v2\/pages\/47\/revisions"}],"predecessor-version":[{"id":255,"href":"http:\/\/localhost:10023\/wp-json\/wp\/v2\/pages\/47\/revisions\/255"}],"wp:attachment":[{"href":"http:\/\/localhost:10023\/wp-json\/wp\/v2\/media?parent=47"}],"curies":[{"name":"wp","href":"https:\/\/api.w.org\/{rel}","templated":true}]}}