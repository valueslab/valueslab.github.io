{"id":47,"date":"2023-09-06T17:38:53","date_gmt":"2023-09-06T17:38:53","guid":{"rendered":"http:\/\/localhost:10023\/?page_id=47"},"modified":"2023-12-31T10:38:33","modified_gmt":"2023-12-31T10:38:33","slug":"research","status":"publish","type":"page","link":"http:\/\/localhost:10023\/research\/","title":{"rendered":"Research"},"content":{"rendered":"\n<p>[Contributors to this list of questions: Qian Cao, Susan Danziger, Jens Haas, Anthony Dyson Hejduk, Helen Han Wei Luo, Katja Maria Vogt, Albert Wenger]<\/p>\n\n\n\n<p>v2023.12.31-1<\/p>\n\n\n\n<p><em>Agency<\/em><\/p>\n\n\n\n<p>\u2014 Are current AIs built as if they pursue their ends? If yes, does this speak for a radical shift, toward models oriented toward human final ends?<\/p>\n\n\n\n<p>\u2014 Should AI try to emulate that human decision-making is fundamentally concerned with sustaining human life and guided by what agents take to be well-lived human lives?<\/p>\n\n\n\n<p>\u2014 Who is responsible for decisions that an AI makes? Is the AI itself responsible, or are its creators responsible for the AI\u2019s decisions?<\/p>\n\n\n\n<p><em>Ethical Values<\/em><\/p>\n\n\n\n<p>\u2014 Are there values, for example, related to the survival of humankind, that neither human beings nor intelligent machines should override?<\/p>\n\n\n\n<p>\u2014 Can the special weight of moral considerations in human reasoning be simulated by an AI?<\/p>\n\n\n\n<p>\u2014 Ethics is concerned with how human beings should live. Does this mean that the AI should ask \u201cwhat should a human agent do?\u201d (as opposed to \u201cwhat should one do?\u201d).<\/p>\n\n\n\n<p><em>Truth and Other Epistemic Values<\/em><\/p>\n\n\n\n<p>\u2014 What is the role of epistemic norms, for example, norms that request attention to evidence, careful thinking, etc., in AI?<\/p>\n\n\n\n<p>\u2014 Is sensitivity to value a separable dimension of AIs, to be added in an additional step? Alternatively, are \u201cethical abilities\u201d integrated dimensions of the \u201cthinking abilities\u201d of AIs, such that they improve along with them?<\/p>\n\n\n\n<p>\u2014 What is an LLM\u2019s relationship to the truth or falsity of its outputs? What does it mean for an LLM to \u201ctell the truth,\u201d \u201clie,\u201d \u201challucinate,\u201d etc.? Can an AI have virtues such as honesty?<\/p>\n\n\n\n<p><em>Mental States<\/em><\/p>\n\n\n\n<p>\u2014 We don\u2019t know whether AIs will ever have mental states such as intentions and beliefs. Lying arguably involves both: an intention to deceive and saying something one believes to be false. Is it a mere metaphor to describe AI-outputs in terms of truth-telling versus lying?<\/p>\n\n\n\n<p>\u2014 An AI may be said to have \u201cinformation\u201d: Does it \u201cbelieve\u201d the things it can provide as information? Does it \u201cknow\u201d them? What are the functional analogues to mental states such as belief and knowledge?<\/p>\n\n\n\n<p>\u2014 How do questions of interpretability of an AI bear on ethics? For example, are ethical\/moral questions ones where it is especially important to not only have the answer, but also to understand how the answer was generated?<\/p>\n\n\n\n<p>\u2014 Should an AI try to emulate the roles of emotion and desiderative\/aversive attitudes in human decision-making? If yes, how?<\/p>\n\n\n\n<p><em>Flawed Thinking<\/em><\/p>\n\n\n\n<p>\u2014 Should value integration start from the premise that an AI ought to help us become better thinkers? How does this premise relate to the frequently asked question of whether AIs are, or will soon become, better &#8216;thinkers&#8217; than we are?<\/p>\n\n\n\n<p>\u2014 Via the corpora of text, images, etc., that LLMs ingest, they inherit flaws of human thinking, e.g., jumping to conclusions, fallacies. Which dimensions of human reasoning do we want to reproduce? Which dimensions of human reasoning can be improved with the help of machines?<\/p>\n\n\n\n<p>\u2014 In human beings, informal fallacies are often treated as \u201cshortcuts\u201d or \u201cfast track\u201d thinking, saving time and mental energy in resource limited environments. Are we aiming for AIs without any such \u201cshortcuts\u201d? If yes, this would constitute a major difference between human and machine reasoning.<\/p>\n\n\n\n<p><em>Pluralism and Disagreement<\/em><\/p>\n\n\n\n<p>\u2014 How can AIs recognize value pluralism, disagreement, and historical changes in evaluative outlooks?<\/p>\n\n\n\n<p>\u2014 Do LLMs that are tailored to particular viewpoints generate &#8220;echo-chamber&#8221;-problems? What are the use cases for working with different outputs from different LLMs?<\/p>\n\n\n\n<p>\u2014 How can AIs recognize that human evaluative outlooks tend to be fragmented and inconsistent, a mix of values, principles, and deep-seated affective attitudes?<\/p>\n\n\n\n<p>\u2014 What is the effect of adding an extensive curriculum in ethics, including works that defend a range of approaches, to the training of an AI?<\/p>\n","protected":false},"excerpt":{"rendered":"<p>[Contributors to this list of questions: Qian Cao, Susan Danziger, Jens Haas, Anthony Dyson Hejduk, Helen Han Wei Luo, Katja Maria Vogt, Albert Wenger] v2023.12.31-1 Agency \u2014 Are current AIs built as if they pursue their ends? If yes, does this speak for a radical shift, toward models oriented toward human final ends? \u2014 Should [&hellip;]<\/p>\n","protected":false},"author":1,"featured_media":0,"parent":0,"menu_order":0,"comment_status":"closed","ping_status":"closed","template":"","meta":{"footnotes":""},"_links":{"self":[{"href":"http:\/\/localhost:10023\/wp-json\/wp\/v2\/pages\/47"}],"collection":[{"href":"http:\/\/localhost:10023\/wp-json\/wp\/v2\/pages"}],"about":[{"href":"http:\/\/localhost:10023\/wp-json\/wp\/v2\/types\/page"}],"author":[{"embeddable":true,"href":"http:\/\/localhost:10023\/wp-json\/wp\/v2\/users\/1"}],"replies":[{"embeddable":true,"href":"http:\/\/localhost:10023\/wp-json\/wp\/v2\/comments?post=47"}],"version-history":[{"count":32,"href":"http:\/\/localhost:10023\/wp-json\/wp\/v2\/pages\/47\/revisions"}],"predecessor-version":[{"id":282,"href":"http:\/\/localhost:10023\/wp-json\/wp\/v2\/pages\/47\/revisions\/282"}],"wp:attachment":[{"href":"http:\/\/localhost:10023\/wp-json\/wp\/v2\/media?parent=47"}],"curies":[{"name":"wp","href":"https:\/\/api.w.org\/{rel}","templated":true}]}}